{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KATTA-00/CO542-Neural-Networks-Labs/blob/main/lab05/E19129)lab05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02cc1fab",
      "metadata": {
        "id": "02cc1fab"
      },
      "source": [
        "# CO542 - Neural Networks and Fuzzy Systems\n",
        "## E/19/129 - K.H. Gunawardana\n",
        "\n",
        "### Lab 05: Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c93cc7e",
      "metadata": {
        "id": "4c93cc7e"
      },
      "source": [
        "### **Installation and Creating a CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d2ef7120",
      "metadata": {
        "id": "d2ef7120",
        "outputId": "7d68ff85-25af-41fb-a5bd-c9a2846aa441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(32 * 13 * 13, 10)  # Assuming input images are 28x28\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of CNN model\n",
        "model = CNN()"
      ],
      "metadata": {
        "id": "h-wyYkbalj1t"
      },
      "id": "h-wyYkbalj1t",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task: Image Classification using CNN (MNIST Dataset)**"
      ],
      "metadata": {
        "id": "79vAuDb1mItM"
      },
      "id": "79vAuDb1mItM"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                # Converts image to PyTorch tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load training and test datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "id": "LAB15rD-mGxO"
      },
      "id": "LAB15rD-mGxO",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # First conv layer: 1 input channel (grayscale), 32 output channels, 3x3 kernel\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.drop1 = nn.Dropout(0.25)\n",
        "\n",
        "        # Second conv layer: 32 input channels, 64 output channels, 3x3 kernel\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.drop2 = nn.Dropout(0.25)\n",
        "\n",
        "        # Third conv layer: 64 input channels, 128 output channels, 3x3 kernel\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.drop3 = nn.Dropout(0.25)\n",
        "\n",
        "        # Calculate output size after conv + pooling: 128x1x1 (approx)\n",
        "        self.fc1 = nn.Linear(128, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10 output classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.drop1(x)\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.drop2(x)\n",
        "        x = self.pool3(F.relu(self.conv3(x)))\n",
        "        x = self.drop3(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hFv1XUYqde_V"
      },
      "id": "hFv1XUYqde_V",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Device configuration (use GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_cnn = CNN().to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "oBnNvhVgd3EK"
      },
      "id": "oBnNvhVgd3EK",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfoU-dIseSuO",
        "outputId": "d96f4317-2e81-422f-ee85-62c170f60dbc"
      },
      "id": "lfoU-dIseSuO",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accuracies = []"
      ],
      "metadata": {
        "id": "oNPda0canLx6"
      },
      "id": "oNPda0canLx6",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model_cnn.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()              # Clear gradients\n",
        "        outputs = model_cnn(images)            # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()                    # Backpropagation\n",
        "        optimizer.step()                   # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ijDP89d3AY",
        "outputId": "b8a79cf5-a6ba-4165-9cd9-5a277327f438"
      },
      "id": "U-ijDP89d3AY",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 2163.5665, Accuracy: 10.49%\n",
            "Epoch [2/5], Loss: 2163.5475, Accuracy: 10.60%\n",
            "Epoch [3/5], Loss: 2163.4179, Accuracy: 10.60%\n",
            "Epoch [4/5], Loss: 2163.8892, Accuracy: 10.43%\n",
            "Epoch [5/5], Loss: 2163.6553, Accuracy: 10.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "model_cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "misclassified_images = []\n",
        "misclassified_labels = []\n",
        "misclassified_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_cnn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Store misclassified\n",
        "        for i in range(len(labels)):\n",
        "            if predicted[i] != labels[i]:\n",
        "                misclassified_images.append(images[i].cpu())\n",
        "                misclassified_labels.append(labels[i].cpu())\n",
        "                misclassified_preds.append(predicted[i].cpu())\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGScWetBd24k",
        "outputId": "6a9c72aa-afaa-4ca7-f35e-2efa2814ad03"
      },
      "id": "hGScWetBd24k",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 9.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def imshow(img):\n",
        "    img = img * 0.5 + 0.5  # Unnormalize from [-1,1] to [0,1]\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Show 6 misclassified images\n",
        "for i in range(6):\n",
        "    plt.title(f\"True: {misclassified_labels[i]}, Pred: {misclassified_preds[i]}\")\n",
        "    imshow(misclassified_images[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nX8dThqod2ri",
        "outputId": "adf890b8-39f5-46a0-a7f4-e668846dab9b"
      },
      "id": "nX8dThqod2ri",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment with different activation functions (e.g., ReLU, LeakyReLU) and compare their performance."
      ],
      "metadata": {
        "id": "w3-IWcjNnXs-"
      },
      "id": "w3-IWcjNnXs-"
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LeakyReLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_LeakyReLU, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.drop1 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.drop2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.drop3 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc1 = nn.Linear(128, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.leaky_relu(self.conv1(x)))\n",
        "        x = self.drop1(x)\n",
        "        x = self.pool2(self.leaky_relu(self.conv2(x)))\n",
        "        x = self.drop2(x)\n",
        "        x = self.pool3(self.leaky_relu(self.conv3(x)))\n",
        "        x = self.drop3(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "R1CTKleWffYY"
      },
      "id": "R1CTKleWffYY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_leaky = CNN_LeakyReLU().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_leaky.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Z2OouS45ffV3"
      },
      "id": "Z2OouS45ffV3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model_leaky.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()              # Clear gradients\n",
        "        outputs = model_leaky(images)            # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()                    # Backpropagation\n",
        "        optimizer.step()                   # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "KhbR_uEiffSU"
      },
      "id": "KhbR_uEiffSU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extend the model to classify CIFAR-10 dataset images."
      ],
      "metadata": {
        "id": "SE4qANSXngBh"
      },
      "id": "SE4qANSXngBh"
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "classes = trainset.classes"
      ],
      "metadata": {
        "id": "u57957peffOa"
      },
      "id": "u57957peffOa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YWq849usffKq"
      },
      "id": "YWq849usffKq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CIFAR10_CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "eA8XbTMjffHd"
      },
      "id": "eA8XbTMjffHd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "A5BBrQB0lDI-"
      },
      "id": "A5BBrQB0lDI-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "outputs = model(images.to(device))\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "print('GroundTruth:', ' '.join(classes[labels[j]] for j in range(4)))\n",
        "print('Predicted:', ' '.join(classes[predicted[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "AKtd4yBKlC-6"
      },
      "id": "AKtd4yBKlC-6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Questions:**"
      ],
      "metadata": {
        "id": "OzE3qdLOlxV9"
      },
      "id": "OzE3qdLOlxV9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How does the CNN classify different digits in the MNIST dataset?"
      ],
      "metadata": {
        "id": "wWTQAz92l3ez"
      },
      "id": "wWTQAz92l3ez"
    },
    {
      "cell_type": "code",
      "source": [
        "# Show what convolutional filters learn (early feature maps)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_feature_maps(model, image):\n",
        "    model.eval()\n",
        "    image = image.unsqueeze(0).to(device)  # Add batch dimension\n",
        "    with torch.no_grad():\n",
        "        x = model_cnn.conv1(image)\n",
        "    fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < x.shape[1]:\n",
        "            ax.imshow(x[0, i].cpu(), cmap='gray')\n",
        "            ax.axis('off')\n",
        "    plt.suptitle(\"Feature Maps After First Conv Layer\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Pass a sample image to visualize filters\n",
        "sample_img, _ = test_dataset[0]\n",
        "visualize_feature_maps(model, sample_img)"
      ],
      "metadata": {
        "id": "Eb7ZN-FilC6x"
      },
      "id": "Eb7ZN-FilC6x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Convolutional Neural Networks (CNNs) classify handwritten digits in the MNIST dataset through hierarchical feature extraction and probabilistic classification. The 28x28 grayscale images, normalized between 0 and 1, are reshaped for CNN input. Early convolutional layers apply small filters (e.g., 3x3 kernels) to detect simple features like edges and corners, visualized as feature maps highlighting key patterns. Deeper layers combine these into complex shapes such as curves and loops. ReLU activations introduce non-linearity for better modeling. Max-pooling layers reduce spatial dimensions, preserving important features and improving computational efficiency and spatial invariance. After convolution and pooling, feature maps are flattened and passed through fully connected layers, culminating in a softmax layer that outputs digit class probabilities. The network is trained using categorical cross-entropy loss and optimized by backpropagation, allowing it to learn filters that specialize in recognizing digit components, thus enabling accurate classification."
      ],
      "metadata": {
        "id": "JaUyIv9job_D"
      },
      "id": "JaUyIv9job_D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compare ReLU and LeakyReLU activation functions. What are the advantages of LeakyReLU?"
      ],
      "metadata": {
        "id": "7sE16fwvpI8k"
      },
      "id": "7sE16fwvpI8k"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Sample input tensor with positive and negative values\n",
        "x = torch.tensor([-3.0, -1.0, 0.0, 1.0, 3.0], requires_grad=True)\n",
        "\n",
        "# Define ReLU and LeakyReLU activation functions\n",
        "relu = nn.ReLU()\n",
        "leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "\n",
        "# Forward pass through ReLU\n",
        "y_relu = relu(x)\n",
        "print(\"ReLU output:\", y_relu)\n",
        "\n",
        "# Forward pass through LeakyReLU\n",
        "y_leaky = leaky_relu(x)\n",
        "print(\"LeakyReLU output:\", y_leaky)\n",
        "\n",
        "# Backward pass to check gradients\n",
        "y_relu.sum().backward(retain_graph=True)\n",
        "print(\"ReLU gradients:\", x.grad)\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "\n",
        "y_leaky.sum().backward()\n",
        "print(\"LeakyReLU gradients:\", x.grad)"
      ],
      "metadata": {
        "id": "qi_9WKHvlC3W"
      },
      "id": "qi_9WKHvlC3W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ReLU (Rectified Linear Unit) and LeakyReLU are popular activation functions used in neural networks, differing mainly in how they handle negative inputs. When tested on an input tensor with both negative and positive values, ReLU outputs zero for all negative inputs, effectively turning off those neurons. This is reflected in its gradient behavior as wellReLU gradients are zero for negative inputs, which can lead to the problem of dying neurons that stop learning because their weights no longer get updated during backpropagation.\n",
        "- In contrast, LeakyReLU allows a small, non-zero output for negative inputs by multiplying them by a small slope (e.g., 0.01). This behavior is clearly seen in the outputs, where LeakyReLU produces small negative values instead of zero, and in its gradients, which remain non-zero for negative inputs. The advantage of LeakyReLUs non-zero gradients is that it prevents neurons from dying and ensures continuous learning across the entire input range. This consistent gradient flow helps stabilize training, especially in deep networks, and can lead to better convergence and improved performance in certain scenarios compared to standard ReLU."
      ],
      "metadata": {
        "id": "L8tVxx1PpgsX"
      },
      "id": "L8tVxx1PpgsX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is the role of MaxPooling layers in CNNs?\n",
        "\n",
        "- MaxPooling layers in Convolutional Neural Networks (CNNs) serve several important functions. Primarily, they reduce the spatial dimensions of feature maps by selecting the maximum value within small windows (e.g., 2x2), which decreases computational complexity and the number of parameters in later layers. This downsampling helps retain the strongest and most salient features while suppressing noise and less important details. MaxPooling also introduces a level of translation invariance, making the model more robust to small shifts or distortions in the input images. By focusing on key features and reducing information overload, MaxPooling layers contribute to improved generalization and help prevent overfitting, ultimately enhancing the CNNs performance on image recognition tasks."
      ],
      "metadata": {
        "id": "6ICxrn7DpgpA"
      },
      "id": "6ICxrn7DpgpA"
    },
    {
      "cell_type": "markdown",
      "id": "3a07c914",
      "metadata": {
        "id": "3a07c914"
      },
      "source": [
        "#### How does dropout improve generalization in neural networks?\n",
        "\n",
        "- Dropout improves generalization in neural networks by preventing overfitting through randomly disabling a fraction of neurons during training. This forces the network to develop independent and redundant feature representations, reducing harmful co-adaptations between neurons. Dropout effectively creates an ensemble of many different subnetworks, which are averaged at test time, enhancing robustness. Additionally, it acts as noise injection that makes the model less sensitive to noisy or corrupted data, improving stability and reducing reliance on specific features. By promoting feature independence and reducing overfitting, dropout helps the network generalize better to unseen data, especially when applied to fully connected layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. What are the key differences when extending the model to classify CIFAR-10 images?\n",
        "\n",
        "- Extending a CNN model from MNIST to CIFAR-10 classification involves several key differences due to CIFAR-10's higher complexity. Unlike MNIST's 28x28 grayscale images, CIFAR-10 consists of 32x32 color images with three RGB channels, requiring the network to process more complex textures and color information. Architecturally, CIFAR-10 models often require deeper networks (5 to 20+ convolutional layers) with techniques like batch normalization and skip connections (e.g., ResNet) to effectively capture hierarchical features and avoid vanishing gradients. Data augmentation such as random flips, rotations, and shifts becomes essential to improve generalization and reduce overfitting on CIFAR-10s more varied dataset. Training parameters also differ, typically involving smaller learning rates, longer training epochs, and optimizers like Adam or AdamW. Furthermore, CIFAR-10 models often employ stronger regularization strategies such as dropout and L2 weight decay. Finally, transfer learning from pre-trained networks on larger datasets can significantly boost performance, addressing CIFAR-10s challenges in feature extraction and limited training data."
      ],
      "metadata": {
        "id": "1w0n4eNZqp9A"
      },
      "id": "1w0n4eNZqp9A"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}